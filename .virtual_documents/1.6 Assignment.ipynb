import pandas as pd
import numpy as np
import spacy
from spacy import displacy
import networkx as nx
import os
import matplotlib.pyplot as plt
import scipy
import re


# Download English module

!python -m spacy download en_core_web_sm


# Load spacy English module

NER = spacy.load("en_core_web_sm")





# Load the book

with open('20th_century.txt', 'r', errors='ignore') as file:
    data = file.read().replace('\n', '')


book = NER(data)


# Visualize identified entities

displacy.render(book[273:500], style = "ent", jupyter = True)





df_sentences = [] # empty shell to store results

# Loop through sentences, get entity list for each sentence
for sent in book.sents:
    entity_list = [ent.text for ent in sent.ents]
    df_sentences.append({"sentence": sent, "entities": entity_list})
    
df_sentences = pd.DataFrame(df_sentences)


df_sentences.head(10)





# Import characters

countries_df = pd.read_csv("countries_list_20th_century_1.5.csv")


countries_df.head()





# Function to filter out entities not of interest

def filter_entity(ent_list, countries_df):
    return [ent for ent in ent_list 
            if ent in list(countries_df['country_name'])]


print(countries_df.columns)



df_sentences['country_entities']=df_sentences['entities'].apply(lambda x: filter_entity(x,countries_df))


countries_df


df_sentences.head(10)


# Check

filter_entity(['Afghanistan'], countries_df)


df_sentences_filter=df_sentences[df_sentences['country_entities'].map(len) > 0]


df_sentences_filter.head()


print(countries_df.columns)






# Defining relationships 

# window size = 5 : this defines how many sentences will be looked at simultaneously 
relationships = [] # create an empty list

for i in range(df_sentences_filter.index[-1]):
    end_i = min(i+5, df_sentences_filter.index[-1])
    country_list = sum((df_sentences_filter.loc[i: end_i].country_entities), [])
    
    # Remove duplicated characters that are next to each other
    country_unique = [country_list[i] for i in range(len(country_list)) 
                   if (i==0) or country_list[i] != country_list[i-1]]
    
    if len(country_unique) > 1:
        for idx, a in enumerate(country_unique[:-1]):
            b = country_unique[idx + 1]
            relationships.append({"source": a, "target": b})


relationship_df = pd.DataFrame(relationships)


relationship_df


# Sort the cases with a->b and b->a

relationship_df = pd.DataFrame(np.sort(relationship_df.values, axis = 1), columns = relationship_df.columns)
relationship_df.head(5)


# Summarize the interactions

relationship_df["value"] = 1
relationship_df = relationship_df.groupby(["source","target"], sort=False, as_index=False).sum()


relationship_df.head(10)


relationship_df.to_csv('country_relationship.csv',index=False)



